[
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "BeautifulSoup",
        "importPath": "bs4",
        "description": "bs4",
        "isExtraImport": true,
        "detail": "bs4",
        "documentation": {}
    },
    {
        "label": "AIAssistant",
        "importPath": "app.genai.ai_assistant",
        "description": "app.genai.ai_assistant",
        "isExtraImport": true,
        "detail": "app.genai.ai_assistant",
        "documentation": {}
    },
    {
        "label": "difflib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "difflib",
        "description": "difflib",
        "detail": "difflib",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "httpx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "httpx",
        "description": "httpx",
        "detail": "httpx",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "sync_playwright",
        "importPath": "playwright.sync_api",
        "description": "playwright.sync_api",
        "isExtraImport": true,
        "detail": "playwright.sync_api",
        "documentation": {}
    },
    {
        "label": "uuid4",
        "importPath": "uuid",
        "description": "uuid",
        "isExtraImport": true,
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "pipeline",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "T5ForConditionalGeneration",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "T5Tokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "ViTForImageClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "ViTFeatureExtractor",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "os,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.",
        "description": "os.",
        "detail": "os.",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "socket,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket.",
        "description": "socket.",
        "detail": "socket.",
        "documentation": {}
    },
    {
        "label": "ThreatIntelScanner",
        "importPath": "app.analyzer.threat_intel",
        "description": "app.analyzer.threat_intel",
        "isExtraImport": true,
        "detail": "app.analyzer.threat_intel",
        "documentation": {}
    },
    {
        "label": "compute_threat_score",
        "importPath": "app.analyzer.threat_intel",
        "description": "app.analyzer.threat_intel",
        "isExtraImport": true,
        "detail": "app.analyzer.threat_intel",
        "documentation": {}
    },
    {
        "label": "ThreatIntelScanner",
        "importPath": "app.analyzer.threat_intel",
        "description": "app.analyzer.threat_intel",
        "isExtraImport": true,
        "detail": "app.analyzer.threat_intel",
        "documentation": {}
    },
    {
        "label": "compute_threat_score",
        "importPath": "app.analyzer.threat_intel",
        "description": "app.analyzer.threat_intel",
        "isExtraImport": true,
        "detail": "app.analyzer.threat_intel",
        "documentation": {}
    },
    {
        "label": "RiskModel",
        "importPath": "app.ml.risk_model",
        "description": "app.ml.risk_model",
        "isExtraImport": true,
        "detail": "app.ml.risk_model",
        "documentation": {}
    },
    {
        "label": "predict_risk_score",
        "importPath": "app.ml.risk_model",
        "description": "app.ml.risk_model",
        "isExtraImport": true,
        "detail": "app.ml.risk_model",
        "documentation": {}
    },
    {
        "label": "RiskModel",
        "importPath": "app.ml.risk_model",
        "description": "app.ml.risk_model",
        "isExtraImport": true,
        "detail": "app.ml.risk_model",
        "documentation": {}
    },
    {
        "label": "AsyncIOMotorClient",
        "importPath": "motor.motor_asyncio",
        "description": "motor.motor_asyncio",
        "isExtraImport": true,
        "detail": "motor.motor_asyncio",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "unquote",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "db_manager",
        "importPath": "app.database.db_manager",
        "description": "app.database.db_manager",
        "isExtraImport": true,
        "detail": "app.database.db_manager",
        "documentation": {}
    },
    {
        "label": "db_manager",
        "importPath": "app.database.db_manager",
        "description": "app.database.db_manager",
        "isExtraImport": true,
        "detail": "app.database.db_manager",
        "documentation": {}
    },
    {
        "label": "APIRouter",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Request",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "StaticFiles",
        "importPath": "fastapi.staticfiles",
        "description": "fastapi.staticfiles",
        "isExtraImport": true,
        "detail": "fastapi.staticfiles",
        "documentation": {}
    },
    {
        "label": "CORSMiddleware",
        "importPath": "fastapi.middleware.cors",
        "description": "fastapi.middleware.cors",
        "isExtraImport": true,
        "detail": "fastapi.middleware.cors",
        "documentation": {}
    },
    {
        "label": "Limiter",
        "importPath": "slowapi",
        "description": "slowapi",
        "isExtraImport": true,
        "detail": "slowapi",
        "documentation": {}
    },
    {
        "label": "_rate_limit_exceeded_handler",
        "importPath": "slowapi",
        "description": "slowapi",
        "isExtraImport": true,
        "detail": "slowapi",
        "documentation": {}
    },
    {
        "label": "get_remote_address",
        "importPath": "slowapi.util",
        "description": "slowapi.util",
        "isExtraImport": true,
        "detail": "slowapi.util",
        "documentation": {}
    },
    {
        "label": "SlowAPIMiddleware",
        "importPath": "slowapi.middleware",
        "description": "slowapi.middleware",
        "isExtraImport": true,
        "detail": "slowapi.middleware",
        "documentation": {}
    },
    {
        "label": "WebsiteFetcher",
        "importPath": "app.analyzer.fetcher",
        "description": "app.analyzer.fetcher",
        "isExtraImport": true,
        "detail": "app.analyzer.fetcher",
        "documentation": {}
    },
    {
        "label": "SecurityChecker",
        "importPath": "app.analyzer.security_checker",
        "description": "app.analyzer.security_checker",
        "isExtraImport": true,
        "detail": "app.analyzer.security_checker",
        "documentation": {}
    },
    {
        "label": "SecurityChecker",
        "importPath": "app.analyzer.security_checker",
        "description": "app.analyzer.security_checker",
        "isExtraImport": true,
        "detail": "app.analyzer.security_checker",
        "documentation": {}
    },
    {
        "label": "PerformanceMonitor",
        "importPath": "app.analyzer.performance_monitor",
        "description": "app.analyzer.performance_monitor",
        "isExtraImport": true,
        "detail": "app.analyzer.performance_monitor",
        "documentation": {}
    },
    {
        "label": "PerformanceMonitor",
        "importPath": "app.analyzer.performance_monitor",
        "description": "app.analyzer.performance_monitor",
        "isExtraImport": true,
        "detail": "app.analyzer.performance_monitor",
        "documentation": {}
    },
    {
        "label": "MalwareScanner",
        "importPath": "app.analyzer.malware_scanner",
        "description": "app.analyzer.malware_scanner",
        "isExtraImport": true,
        "detail": "app.analyzer.malware_scanner",
        "documentation": {}
    },
    {
        "label": "ContextualAnalyzer",
        "importPath": "app.analyzer.contextual_analyzer",
        "description": "app.analyzer.contextual_analyzer",
        "isExtraImport": true,
        "detail": "app.analyzer.contextual_analyzer",
        "documentation": {}
    },
    {
        "label": "predict_risk_score",
        "importPath": "app.analyzer.risk_calculator",
        "description": "app.analyzer.risk_calculator",
        "isExtraImport": true,
        "detail": "app.analyzer.risk_calculator",
        "documentation": {}
    },
    {
        "label": "summarize_anomalies",
        "importPath": "app.analyzer.nlp_utils",
        "description": "app.analyzer.nlp_utils",
        "isExtraImport": true,
        "detail": "app.analyzer.nlp_utils",
        "documentation": {}
    },
    {
        "label": "classify_screenshot",
        "importPath": "app.image_classifier",
        "description": "app.image_classifier",
        "isExtraImport": true,
        "detail": "app.image_classifier",
        "documentation": {}
    },
    {
        "label": "classify_screenshot",
        "importPath": "app.image_classifier",
        "description": "app.image_classifier",
        "isExtraImport": true,
        "detail": "app.image_classifier",
        "documentation": {}
    },
    {
        "label": "RecommendationEngine",
        "importPath": "app.analyzer.utils",
        "description": "app.analyzer.utils",
        "isExtraImport": true,
        "detail": "app.analyzer.utils",
        "documentation": {}
    },
    {
        "label": "AnalyzeRequest",
        "importPath": "app.models",
        "description": "app.models",
        "isExtraImport": true,
        "detail": "app.models",
        "documentation": {}
    },
    {
        "label": "ExtendedAnalyzeResponse",
        "importPath": "app.models",
        "description": "app.models",
        "isExtraImport": true,
        "detail": "app.models",
        "documentation": {}
    },
    {
        "label": "ScanComparison",
        "importPath": "app.models",
        "description": "app.models",
        "isExtraImport": true,
        "detail": "app.models",
        "documentation": {}
    },
    {
        "label": "Anomaly",
        "importPath": "app.models",
        "description": "app.models",
        "isExtraImport": true,
        "detail": "app.models",
        "documentation": {}
    },
    {
        "label": "SEOMetadata",
        "importPath": "app.models",
        "description": "app.models",
        "isExtraImport": true,
        "detail": "app.models",
        "documentation": {}
    },
    {
        "label": "ThreatIntel",
        "importPath": "app.models",
        "description": "app.models",
        "isExtraImport": true,
        "detail": "app.models",
        "documentation": {}
    },
    {
        "label": "SEOScanner",
        "importPath": "app.analyzer.seo_scanner",
        "description": "app.analyzer.seo_scanner",
        "isExtraImport": true,
        "detail": "app.analyzer.seo_scanner",
        "documentation": {}
    },
    {
        "label": "SEOScanner",
        "importPath": "app.analyzer.seo_scanner",
        "description": "app.analyzer.seo_scanner",
        "isExtraImport": true,
        "detail": "app.analyzer.seo_scanner",
        "documentation": {}
    },
    {
        "label": "AccessibilityScanner",
        "importPath": "app.analyzer.accessibility_scanner",
        "description": "app.analyzer.accessibility_scanner",
        "isExtraImport": true,
        "detail": "app.analyzer.accessibility_scanner",
        "documentation": {}
    },
    {
        "label": "gen_anomaly_summary",
        "importPath": "app.analyzer.ai_utils",
        "description": "app.analyzer.ai_utils",
        "isExtraImport": true,
        "detail": "app.analyzer.ai_utils",
        "documentation": {}
    },
    {
        "label": "gen_fix_snippet",
        "importPath": "app.analyzer.ai_utils",
        "description": "app.analyzer.ai_utils",
        "isExtraImport": true,
        "detail": "app.analyzer.ai_utils",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "AccessibilityScanner",
        "kind": 6,
        "importPath": "Backend.app.analyzer.accessibility_scanner",
        "description": "Backend.app.analyzer.accessibility_scanner",
        "peekOfCode": "class AccessibilityScanner:\n    @staticmethod\n    def scan(html: str):\n        soup = BeautifulSoup(html, \"html.parser\")\n        issues = []\n        # 1. Missing alt attributes\n        images = soup.find_all(\"img\")\n        for img in images:\n            if not img.get(\"alt\"):\n                issues.append({",
        "detail": "Backend.app.analyzer.accessibility_scanner",
        "documentation": {}
    },
    {
        "label": "gen_anomaly_summary",
        "kind": 2,
        "importPath": "Backend.app.analyzer.ai_utils",
        "description": "Backend.app.analyzer.ai_utils",
        "peekOfCode": "def gen_anomaly_summary(anomalies: list) -> str:\n    return assistant.summarize_anomalies(anomalies)\ndef gen_fix_snippet(anomaly: dict) -> str:\n    return assistant.generate_fix_suggestion(anomaly)",
        "detail": "Backend.app.analyzer.ai_utils",
        "documentation": {}
    },
    {
        "label": "gen_fix_snippet",
        "kind": 2,
        "importPath": "Backend.app.analyzer.ai_utils",
        "description": "Backend.app.analyzer.ai_utils",
        "peekOfCode": "def gen_fix_snippet(anomaly: dict) -> str:\n    return assistant.generate_fix_suggestion(anomaly)",
        "detail": "Backend.app.analyzer.ai_utils",
        "documentation": {}
    },
    {
        "label": "assistant",
        "kind": 5,
        "importPath": "Backend.app.analyzer.ai_utils",
        "description": "Backend.app.analyzer.ai_utils",
        "peekOfCode": "assistant = AIAssistant(model_name=\"google/flan-t5-base\")   \ndef gen_anomaly_summary(anomalies: list) -> str:\n    return assistant.summarize_anomalies(anomalies)\ndef gen_fix_snippet(anomaly: dict) -> str:\n    return assistant.generate_fix_suggestion(anomaly)",
        "detail": "Backend.app.analyzer.ai_utils",
        "documentation": {}
    },
    {
        "label": "compare_content",
        "kind": 2,
        "importPath": "Backend.app.analyzer.content_comparator",
        "description": "Backend.app.analyzer.content_comparator",
        "peekOfCode": "def compare_content(old_html: str, new_html: str) -> dict:\n    \"\"\"\n    Compares two HTML texts. Returns the ratio of similarity.\n    \"\"\"\n    seq = difflib.SequenceMatcher(None, old_html, new_html)\n    similarity_ratio = seq.ratio()  # 1.0 means identical, 0 means completely different\n    return {\n        \"similarity\": similarity_ratio,\n        \"message\": f\"Content similarity is {similarity_ratio * 100:.2f}%\"\n    }",
        "detail": "Backend.app.analyzer.content_comparator",
        "documentation": {}
    },
    {
        "label": "ContextualAnalyzer",
        "kind": 6,
        "importPath": "Backend.app.analyzer.contextual_analyzer",
        "description": "Backend.app.analyzer.contextual_analyzer",
        "peekOfCode": "class ContextualAnalyzer:\n    KNOWN_SAFE_SITES = {\n        'wikipedia.org': {\n            'allowed_missing_headers': ['X-Frame-Options'],\n            'expected_load_time': 800  # in ms\n        }\n    }\n    @classmethod\n    def apply_context(cls, url: str, anomalies: list) -> list:\n        \"\"\"",
        "detail": "Backend.app.analyzer.contextual_analyzer",
        "documentation": {}
    },
    {
        "label": "EnhancedFetcher",
        "kind": 6,
        "importPath": "Backend.app.analyzer.enhanced_fetcher",
        "description": "Backend.app.analyzer.enhanced_fetcher",
        "peekOfCode": "class EnhancedFetcher:\n    @staticmethod\n    async def get_actual_headers(url: str) -> Dict:\n        \"\"\"Get headers without following redirects\"\"\"\n        async with httpx.AsyncClient() as client:\n            response = await client.head(\n                url,\n                follow_redirects=False,\n                timeout=10.0\n            )",
        "detail": "Backend.app.analyzer.enhanced_fetcher",
        "documentation": {}
    },
    {
        "label": "WebsiteFetcher",
        "kind": 6,
        "importPath": "Backend.app.analyzer.fetcher",
        "description": "Backend.app.analyzer.fetcher",
        "peekOfCode": "class WebsiteFetcher:\n    USER_AGENT = (\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n        \"Chrome/122.0.0.0 Safari/537.36\"\n    )\n    DEFAULT_TIMEOUT = 30.0\n    @staticmethod\n    async def get_screenshot(url: str) -> Optional[str]:\n        try:",
        "detail": "Backend.app.analyzer.fetcher",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "Backend.app.analyzer.fetcher",
        "description": "Backend.app.analyzer.fetcher",
        "peekOfCode": "logger = logging.getLogger(__name__)\nBASE_DIR = Path(__file__).resolve().parent\nSCREENSHOT_DIR = Path(\"static/screenshots\")\nclass WebsiteFetcher:\n    USER_AGENT = (\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n        \"Chrome/122.0.0.0 Safari/537.36\"\n    )\n    DEFAULT_TIMEOUT = 30.0",
        "detail": "Backend.app.analyzer.fetcher",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "Backend.app.analyzer.fetcher",
        "description": "Backend.app.analyzer.fetcher",
        "peekOfCode": "BASE_DIR = Path(__file__).resolve().parent\nSCREENSHOT_DIR = Path(\"static/screenshots\")\nclass WebsiteFetcher:\n    USER_AGENT = (\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n        \"Chrome/122.0.0.0 Safari/537.36\"\n    )\n    DEFAULT_TIMEOUT = 30.0\n    @staticmethod",
        "detail": "Backend.app.analyzer.fetcher",
        "documentation": {}
    },
    {
        "label": "SCREENSHOT_DIR",
        "kind": 5,
        "importPath": "Backend.app.analyzer.fetcher",
        "description": "Backend.app.analyzer.fetcher",
        "peekOfCode": "SCREENSHOT_DIR = Path(\"static/screenshots\")\nclass WebsiteFetcher:\n    USER_AGENT = (\n        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n        \"Chrome/122.0.0.0 Safari/537.36\"\n    )\n    DEFAULT_TIMEOUT = 30.0\n    @staticmethod\n    async def get_screenshot(url: str) -> Optional[str]:",
        "detail": "Backend.app.analyzer.fetcher",
        "documentation": {}
    },
    {
        "label": "capture_screenshot",
        "kind": 2,
        "importPath": "Backend.app.analyzer.get_screenshot_sync",
        "description": "Backend.app.analyzer.get_screenshot_sync",
        "peekOfCode": "def capture_screenshot(url: str):\n    # Define the screenshot directory – ensure it matches what you use in fetcher.py\n    screenshot_dir = Path(\"static/screenshots\")\n    screenshot_dir.mkdir(parents=True, exist_ok=True)\n    # Create a unique filename\n    filename = f\"{uuid4().hex}.png\"\n    filepath = screenshot_dir / filename\n    # Use Playwright's synchronous API to capture a screenshot with HTTPS errors ignored\n    with sync_playwright() as p:\n        browser = p.chromium.launch(headless=True)",
        "detail": "Backend.app.analyzer.get_screenshot_sync",
        "documentation": {}
    },
    {
        "label": "MalwareScanner",
        "kind": 6,
        "importPath": "Backend.app.analyzer.malware_scanner",
        "description": "Backend.app.analyzer.malware_scanner",
        "peekOfCode": "class MalwareScanner:\n    # Known malicious patterns (simplified examples)\n    PATTERNS = [\n        (r\"<script>.*?eval\\(.*?\\)</script>\", \"Potential malicious script (eval)\"),\n        (r\"<iframe.*?src=.*?hidden\", \"Hidden iframe detected\"),\n        (r\"document\\.write\\(unescape\\(\", \"Potential obfuscated code\")\n    ]\n    @classmethod\n    def scan_for_malware(cls, html: str) -> List[Dict]:\n        \"\"\"Scan HTML for malicious patterns\"\"\"",
        "detail": "Backend.app.analyzer.malware_scanner",
        "documentation": {}
    },
    {
        "label": "summarize_anomalies",
        "kind": 2,
        "importPath": "Backend.app.analyzer.nlp_utils",
        "description": "Backend.app.analyzer.nlp_utils",
        "peekOfCode": "def summarize_anomalies(anomalies: list) -> str:\n    text = \" \".join(anomaly[\"message\"] for anomaly in anomalies if \"message\" in anomaly)\n    if not text:\n        return \"No significant anomalies found.\"\n    # Adjust max_length if text is short\n    input_length = len(text.split())\n    max_length = 100 if input_length > 50 else 12  # Example logic\n    summary = summarizer(text, max_length=max_length, min_length=5, do_sample=False)\n    return summary[0][\"summary_text\"]",
        "detail": "Backend.app.analyzer.nlp_utils",
        "documentation": {}
    },
    {
        "label": "summarizer",
        "kind": 5,
        "importPath": "Backend.app.analyzer.nlp_utils",
        "description": "Backend.app.analyzer.nlp_utils",
        "peekOfCode": "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\ndef summarize_anomalies(anomalies: list) -> str:\n    text = \" \".join(anomaly[\"message\"] for anomaly in anomalies if \"message\" in anomaly)\n    if not text:\n        return \"No significant anomalies found.\"\n    # Adjust max_length if text is short\n    input_length = len(text.split())\n    max_length = 100 if input_length > 50 else 12  # Example logic\n    summary = summarizer(text, max_length=max_length, min_length=5, do_sample=False)\n    return summary[0][\"summary_text\"]",
        "detail": "Backend.app.analyzer.nlp_utils",
        "documentation": {}
    },
    {
        "label": "PerformanceMonitor",
        "kind": 6,
        "importPath": "Backend.app.analyzer.performance_monitor",
        "description": "Backend.app.analyzer.performance_monitor",
        "peekOfCode": "class PerformanceMonitor:\n    # Thresholds in seconds\n    THRESHOLDS = {\n        \"excellent\": 1.0,\n        \"good\": 2.0,\n        \"poor\": 3.0\n    }\n    @classmethod\n    def check_performance(cls, response_time: float) -> List[Dict]:\n        \"\"\"Analyze website performance metrics\"\"\"",
        "detail": "Backend.app.analyzer.performance_monitor",
        "documentation": {}
    },
    {
        "label": "predict_risk_score",
        "kind": 2,
        "importPath": "Backend.app.analyzer.risk_calculator",
        "description": "Backend.app.analyzer.risk_calculator",
        "peekOfCode": "def predict_risk_score(features: Dict) -> int:\n    feature_names = [\"security_count\", \"performance_count\", \"avg_severity\", \"load_time_ms\", \"page_size_kb\"]\n    # Use a pandas DataFrame to align feature names\n    X = pd.DataFrame([[features.get(f, 0) for f in feature_names]], columns=feature_names)\n    return int(risk_model.predict(X)[0])",
        "detail": "Backend.app.analyzer.risk_calculator",
        "documentation": {}
    },
    {
        "label": "risk_model",
        "kind": 5,
        "importPath": "Backend.app.analyzer.risk_calculator",
        "description": "Backend.app.analyzer.risk_calculator",
        "peekOfCode": "risk_model = joblib.load(\"risk_model.pkl\")\ndef predict_risk_score(features: Dict) -> int:\n    feature_names = [\"security_count\", \"performance_count\", \"avg_severity\", \"load_time_ms\", \"page_size_kb\"]\n    # Use a pandas DataFrame to align feature names\n    X = pd.DataFrame([[features.get(f, 0) for f in feature_names]], columns=feature_names)\n    return int(risk_model.predict(X)[0])",
        "detail": "Backend.app.analyzer.risk_calculator",
        "documentation": {}
    },
    {
        "label": "SecurityChecker",
        "kind": 6,
        "importPath": "Backend.app.analyzer.security_checker",
        "description": "Backend.app.analyzer.security_checker",
        "peekOfCode": "class SecurityChecker:\n    # Required security headers and recommendations\n    REQUIRED_HEADERS = {\n        \"Content-Security-Policy\": {\n            \"severity\": \"high\",\n            \"recommendation\": \"Implement Content-Security-Policy to prevent XSS attacks.\"\n        },\n        \"X-Frame-Options\": {\n            \"severity\": \"medium\",\n            \"recommendation\": \"Add X-Frame-Options to protect against clickjacking.\"",
        "detail": "Backend.app.analyzer.security_checker",
        "documentation": {}
    },
    {
        "label": "SEOScanner",
        "kind": 6,
        "importPath": "Backend.app.analyzer.seo_scanner",
        "description": "Backend.app.analyzer.seo_scanner",
        "peekOfCode": "class SEOScanner:\n    @staticmethod\n    def scan(html: str, url: str):\n        soup = BeautifulSoup(html, \"html.parser\")\n        issues = []\n        metadata = {}\n        # 1. Title tag\n        title_tag = soup.title.string if soup.title else None\n        metadata[\"title\"] = title_tag\n        if not title_tag or len(title_tag.strip()) < 10:",
        "detail": "Backend.app.analyzer.seo_scanner",
        "documentation": {}
    },
    {
        "label": "ThreatIntelScanner",
        "kind": 6,
        "importPath": "Backend.app.analyzer.threat_intel",
        "description": "Backend.app.analyzer.threat_intel",
        "peekOfCode": "class ThreatIntelScanner:\n    ABUSE_API_KEY = \"f7e4c1f923fcedea0b1aa3cdcaf87fb15052ff1d34731752bfb554c43a330dd13445db97239d780f\"\n    @staticmethod\n    async def check_virustotal(domain: str) -> Dict:\n        \"\"\"Query VirusTotal for domain verdicts with detailed metadata.\"\"\"\n        url = f\"https://www.virustotal.com/api/v3/domains/{domain}\"\n        headers = {\"x-apikey\": VT_API_KEY}\n        try:\n            async with httpx.AsyncClient() as client:\n                resp = await client.get(url, headers=headers, timeout=15.0)",
        "detail": "Backend.app.analyzer.threat_intel",
        "documentation": {}
    },
    {
        "label": "compute_threat_score",
        "kind": 2,
        "importPath": "Backend.app.analyzer.threat_intel",
        "description": "Backend.app.analyzer.threat_intel",
        "peekOfCode": "def compute_threat_score(vt: Dict, abuse: Dict) -> int:\n    \"\"\"\n    Combine VT score (0–100) and AbuseIPDB score (0–100)\n    with a weighted formula: 70% VT, 30% AbuseIPDB.\n    \"\"\"\n    try:\n        return int(vt.get(\"vt_score\", 0) * 0.7 + abuse.get(\"confidenceScore\", 0) * 0.3)\n    except Exception:\n        return 0",
        "detail": "Backend.app.analyzer.threat_intel",
        "documentation": {}
    },
    {
        "label": "VT_API_KEY",
        "kind": 5,
        "importPath": "Backend.app.analyzer.threat_intel",
        "description": "Backend.app.analyzer.threat_intel",
        "peekOfCode": "VT_API_KEY = os.getenv(\"VIRUSTOTAL_API_KEY\")\n# AbuseIPDB key hardcoded below\nclass ThreatIntelScanner:\n    ABUSE_API_KEY = \"f7e4c1f923fcedea0b1aa3cdcaf87fb15052ff1d34731752bfb554c43a330dd13445db97239d780f\"\n    @staticmethod\n    async def check_virustotal(domain: str) -> Dict:\n        \"\"\"Query VirusTotal for domain verdicts with detailed metadata.\"\"\"\n        url = f\"https://www.virustotal.com/api/v3/domains/{domain}\"\n        headers = {\"x-apikey\": VT_API_KEY}\n        try:",
        "detail": "Backend.app.analyzer.threat_intel",
        "documentation": {}
    },
    {
        "label": "RecommendationEngine",
        "kind": 6,
        "importPath": "Backend.app.analyzer.utils",
        "description": "Backend.app.analyzer.utils",
        "peekOfCode": "class RecommendationEngine:\n    # Full header → (friendly text, config snippet)\n    HEADER_ADVICE = {\n        \"Content-Security-Policy\": (\n            \"Prevent XSS by restricting sources of scripts/styles/etc.\",\n            \"Content-Security-Policy: default-src 'self';\"\n        ),\n        \"X-Frame-Options\": (\n            \"Protect against clickjacking by controlling framing policy.\",\n            \"X-Frame-Options: DENY\"",
        "detail": "Backend.app.analyzer.utils",
        "documentation": {}
    },
    {
        "label": "DatabaseManager",
        "kind": 6,
        "importPath": "Backend.app.database.db_manager",
        "description": "Backend.app.database.db_manager",
        "peekOfCode": "class DatabaseManager:\n    def __init__(self):\n        # Point at your Mongo URI (or default to localhost)\n        self.client = AsyncIOMotorClient(\n            os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\")\n        )\n        self.db = self.client.website_analyzer\n    async def initialize(self):\n        \"\"\"Create indexes for optimal query performance\"\"\"\n        await self.db.scans.create_index(\"scan_metadata.scan_date\")",
        "detail": "Backend.app.database.db_manager",
        "documentation": {}
    },
    {
        "label": "db_manager",
        "kind": 5,
        "importPath": "Backend.app.database.db_manager",
        "description": "Backend.app.database.db_manager",
        "peekOfCode": "db_manager = DatabaseManager()",
        "detail": "Backend.app.database.db_manager",
        "documentation": {}
    },
    {
        "label": "AIAssistant",
        "kind": 6,
        "importPath": "Backend.app.genai.ai_assistant",
        "description": "Backend.app.genai.ai_assistant",
        "peekOfCode": "class AIAssistant:\n    def __init__(self, model_name=\"google/flan-t5-small\"):  # <- better default\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n        self.model = T5ForConditionalGeneration.from_pretrained(model_name).to(self.device)\n    def generate_fix_suggestion(self, anomaly: dict) -> str:\n        try:\n            required_keys = {\"type\", \"message\", \"severity\"}\n            if not required_keys.issubset(anomaly.keys()):\n                return \"Invalid anomaly format.\"",
        "detail": "Backend.app.genai.ai_assistant",
        "documentation": {}
    },
    {
        "label": "RiskModel",
        "kind": 6,
        "importPath": "Backend.app.ml.risk_model",
        "description": "Backend.app.ml.risk_model",
        "peekOfCode": "class RiskModel:\n    SEVERITY_WEIGHTS = {'low': 1, 'medium': 2, 'high': 3}\n    def __init__(self):\n        self.model = RandomForestRegressor(n_estimators=100, random_state=42)\n        self.features = [\n            'security_count', \n            'performance_count',\n            'avg_severity',\n            'load_time_ms',\n            'page_size_kb'",
        "detail": "Backend.app.ml.risk_model",
        "documentation": {}
    },
    {
        "label": "predict_risk_score",
        "kind": 2,
        "importPath": "Backend.app.ml.risk_model",
        "description": "Backend.app.ml.risk_model",
        "peekOfCode": "def predict_risk_score(features: dict) -> int:\n    return risk_model.predict(features)",
        "detail": "Backend.app.ml.risk_model",
        "documentation": {}
    },
    {
        "label": "risk_model",
        "kind": 5,
        "importPath": "Backend.app.ml.risk_model",
        "description": "Backend.app.ml.risk_model",
        "peekOfCode": "risk_model = RiskModel()\ndef predict_risk_score(features: dict) -> int:\n    return risk_model.predict(features)",
        "detail": "Backend.app.ml.risk_model",
        "documentation": {}
    },
    {
        "label": "router",
        "kind": 5,
        "importPath": "Backend.app.routes.training",
        "description": "Backend.app.routes.training",
        "peekOfCode": "router = APIRouter()\nmodel = RiskModel()\n@router.post(\"/train\")\nasync def train_model():\n    results = await model.train()\n    return {\n        \"status\": \"training_complete\",\n        \"model_performance\": results\n    }",
        "detail": "Backend.app.routes.training",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "Backend.app.routes.training",
        "description": "Backend.app.routes.training",
        "peekOfCode": "model = RiskModel()\n@router.post(\"/train\")\nasync def train_model():\n    results = await model.train()\n    return {\n        \"status\": \"training_complete\",\n        \"model_performance\": results\n    }",
        "detail": "Backend.app.routes.training",
        "documentation": {}
    },
    {
        "label": "classify_screenshot",
        "kind": 2,
        "importPath": "Backend.app.image_classifier",
        "description": "Backend.app.image_classifier",
        "peekOfCode": "def classify_screenshot(image_path: str) -> str:\n    # Open the image\n    image = Image.open(image_path)\n    # Ensure image is in RGB mode\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    # Preprocess the image for the model\n    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n    # Run inference without gradient calculation\n    with torch.no_grad():",
        "detail": "Backend.app.image_classifier",
        "documentation": {}
    },
    {
        "label": "model_name",
        "kind": 5,
        "importPath": "Backend.app.image_classifier",
        "description": "Backend.app.image_classifier",
        "peekOfCode": "model_name = \"google/vit-base-patch16-224\"\nfeature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\nmodel = ViTForImageClassification.from_pretrained(model_name)\ndef classify_screenshot(image_path: str) -> str:\n    # Open the image\n    image = Image.open(image_path)\n    # Ensure image is in RGB mode\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    # Preprocess the image for the model",
        "detail": "Backend.app.image_classifier",
        "documentation": {}
    },
    {
        "label": "feature_extractor",
        "kind": 5,
        "importPath": "Backend.app.image_classifier",
        "description": "Backend.app.image_classifier",
        "peekOfCode": "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\nmodel = ViTForImageClassification.from_pretrained(model_name)\ndef classify_screenshot(image_path: str) -> str:\n    # Open the image\n    image = Image.open(image_path)\n    # Ensure image is in RGB mode\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    # Preprocess the image for the model\n    inputs = feature_extractor(images=image, return_tensors=\"pt\")",
        "detail": "Backend.app.image_classifier",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "Backend.app.image_classifier",
        "description": "Backend.app.image_classifier",
        "peekOfCode": "model = ViTForImageClassification.from_pretrained(model_name)\ndef classify_screenshot(image_path: str) -> str:\n    # Open the image\n    image = Image.open(image_path)\n    # Ensure image is in RGB mode\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    # Preprocess the image for the model\n    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n    # Run inference without gradient calculation",
        "detail": "Backend.app.image_classifier",
        "documentation": {}
    },
    {
        "label": "normalize_url",
        "kind": 2,
        "importPath": "Backend.app.main",
        "description": "Backend.app.main",
        "peekOfCode": "def normalize_url(url: str) -> str:\n    p = urlparse(url)\n    if not p.scheme:\n        return f\"https://{url}\"\n    return url\n@app.post(\"/analyze\", response_model=ExtendedAnalyzeResponse)\n@limiter.limit(\"5/minute\")\nasync def analyze_website(request: Request, payload: AnalyzeRequest):\n    url = normalize_url(payload.url)\n    logger.info(f\"Starting analysis for URL: {url}\")",
        "detail": "Backend.app.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "Backend.app.main",
        "description": "Backend.app.main",
        "peekOfCode": "app = FastAPI(\n    title=\"Website Anomaly Detector\",\n    description=\"API for detecting security and performance anomalies in websites\",\n    version=\"1.0.0\"\n)\n# CORS (so your React/Vite app can call /analyze)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # tighten in prod!\n    allow_credentials=True,",
        "detail": "Backend.app.main",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "Backend.app.main",
        "description": "Backend.app.main",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlimiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\napp.add_exception_handler(429, _rate_limit_exceeded_handler)\napp.add_middleware(SlowAPIMiddleware)\ndef normalize_url(url: str) -> str:\n    p = urlparse(url)\n    if not p.scheme:\n        return f\"https://{url}\"\n    return url",
        "detail": "Backend.app.main",
        "documentation": {}
    },
    {
        "label": "limiter",
        "kind": 5,
        "importPath": "Backend.app.main",
        "description": "Backend.app.main",
        "peekOfCode": "limiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\napp.add_exception_handler(429, _rate_limit_exceeded_handler)\napp.add_middleware(SlowAPIMiddleware)\ndef normalize_url(url: str) -> str:\n    p = urlparse(url)\n    if not p.scheme:\n        return f\"https://{url}\"\n    return url\n@app.post(\"/analyze\", response_model=ExtendedAnalyzeResponse)",
        "detail": "Backend.app.main",
        "documentation": {}
    },
    {
        "label": "app.state.limiter",
        "kind": 5,
        "importPath": "Backend.app.main",
        "description": "Backend.app.main",
        "peekOfCode": "app.state.limiter = limiter\napp.add_exception_handler(429, _rate_limit_exceeded_handler)\napp.add_middleware(SlowAPIMiddleware)\ndef normalize_url(url: str) -> str:\n    p = urlparse(url)\n    if not p.scheme:\n        return f\"https://{url}\"\n    return url\n@app.post(\"/analyze\", response_model=ExtendedAnalyzeResponse)\n@limiter.limit(\"5/minute\")",
        "detail": "Backend.app.main",
        "documentation": {}
    },
    {
        "label": "Severity",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class Severity(str, Enum):\n    HIGH   = \"high\"\n    MEDIUM = \"medium\"\n    LOW    = \"low\"\nclass Anomaly(BaseModel):\n    type: str\n    message: str\n    severity: Severity\n    recommendation: Optional[str] = None\nclass AnalyzeRequest(BaseModel):",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "Anomaly",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class Anomaly(BaseModel):\n    type: str\n    message: str\n    severity: Severity\n    recommendation: Optional[str] = None\nclass AnalyzeRequest(BaseModel):\n    url: str\nclass SEOMetadata(BaseModel):\n    title:             Optional[str] = None\n    meta_description:  Optional[str] = None",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeRequest",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class AnalyzeRequest(BaseModel):\n    url: str\nclass SEOMetadata(BaseModel):\n    title:             Optional[str] = None\n    meta_description:  Optional[str] = None\n    canonical:         Optional[str] = None\n    h1_count:          Optional[int] = None\nclass ThreatIntelVT(BaseModel):\n    category:        Optional[str] = None\n    malicious_count: Optional[int] = None",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "SEOMetadata",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class SEOMetadata(BaseModel):\n    title:             Optional[str] = None\n    meta_description:  Optional[str] = None\n    canonical:         Optional[str] = None\n    h1_count:          Optional[int] = None\nclass ThreatIntelVT(BaseModel):\n    category:        Optional[str] = None\n    malicious_count: Optional[int] = None\n    total_engines:   Optional[int] = None\n    vt_score:        Optional[int] = None",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "ThreatIntelVT",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class ThreatIntelVT(BaseModel):\n    category:        Optional[str] = None\n    malicious_count: Optional[int] = None\n    total_engines:   Optional[int] = None\n    vt_score:        Optional[int] = None\n    last_analysis:   Optional[datetime] = None\n    flagged_engines: Optional[List[str]] = None\nclass ThreatIntelAbuse(BaseModel):\n    category:        str\n    confidenceScore: int",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "ThreatIntelAbuse",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class ThreatIntelAbuse(BaseModel):\n    category:        str\n    confidenceScore: int\n    total_reports:   Optional[int]     = None\n    last_reported:   Optional[datetime] = None\n    country:         Optional[str]     = None\n    ip:              Optional[str]     = None\n    isp:             Optional[str]     = None\n    domain:          Optional[str]     = None\n    usage_type:      Optional[str]     = None",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "ThreatIntel",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class ThreatIntel(BaseModel):\n    virustotal:   Optional[ThreatIntelVT] = None\n    abuse_ip_db:  Optional[ThreatIntelAbuse] = None\n    combined_score: float\nclass ScanComparison(BaseModel):\n    new_issues:        List[str]\n    resolved_issues:   List[str]\n    persistent_issues: List[str]\n    risk_score_change: Optional[int] = None\nclass AnalyzeResponse(BaseModel):",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "ScanComparison",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class ScanComparison(BaseModel):\n    new_issues:        List[str]\n    resolved_issues:   List[str]\n    persistent_issues: List[str]\n    risk_score_change: Optional[int] = None\nclass AnalyzeResponse(BaseModel):\n    url:                 str\n    risk_score:          int\n    anomalies:           List[Anomaly]\n    screenshot:          Optional[str] = None",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "AnalyzeResponse",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class AnalyzeResponse(BaseModel):\n    url:                 str\n    risk_score:          int\n    anomalies:           List[Anomaly]\n    screenshot:          Optional[str] = None\n    recommendations:     List[str]\n    previous_scan_diff:  Optional[ScanComparison] = None\n    seo_metadata:        Optional[SEOMetadata]    = None\n    threat_intel:        Optional[ThreatIntel]    = None\n    ai_summary:          Optional[str] = None",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "ExtendedAnalyzeResponse",
        "kind": 6,
        "importPath": "Backend.app.models",
        "description": "Backend.app.models",
        "peekOfCode": "class ExtendedAnalyzeResponse(AnalyzeResponse):\n    risk_level:       str\n    scan_metadata:    Dict[str, Any]\n    security_headers: Dict[str, Any]\n    page_stats:       Dict[str, Any]",
        "detail": "Backend.app.models",
        "documentation": {}
    },
    {
        "label": "image_path",
        "kind": 5,
        "importPath": "Backend.app.ttest_image_classifier",
        "description": "Backend.app.ttest_image_classifier",
        "peekOfCode": "image_path = \"static/screenshots/your_screenshot_filename.png\"\nlabel = classify_screenshot(image_path)\nprint(f\"Predicted label: {label}\")",
        "detail": "Backend.app.ttest_image_classifier",
        "documentation": {}
    },
    {
        "label": "label",
        "kind": 5,
        "importPath": "Backend.app.ttest_image_classifier",
        "description": "Backend.app.ttest_image_classifier",
        "peekOfCode": "label = classify_screenshot(image_path)\nprint(f\"Predicted label: {label}\")",
        "detail": "Backend.app.ttest_image_classifier",
        "documentation": {}
    },
    {
        "label": "test_performance_monitor_with_various_times",
        "kind": 2,
        "importPath": "Backend.tests.test_performance_monitor",
        "description": "Backend.tests.test_performance_monitor",
        "peekOfCode": "def test_performance_monitor_with_various_times(response_time, expected_count, expected_severity):\n    \"\"\"\n    Tests the performance monitor with different response times to ensure\n    it produces the correct number and severity of anomalies for each case.\n    \"\"\"\n    # Act: Run the performance check with the current test case's response time\n    anomalies = PerformanceMonitor.check_performance(response_time)\n    # Assert: Check if the number of anomalies is what we expect for this case\n    assert len(anomalies) == expected_count\n    # If we expected an anomaly, also check if its severity is correct",
        "detail": "Backend.tests.test_performance_monitor",
        "documentation": {}
    },
    {
        "label": "performance_test_cases",
        "kind": 5,
        "importPath": "Backend.tests.test_performance_monitor",
        "description": "Backend.tests.test_performance_monitor",
        "peekOfCode": "performance_test_cases = [\n    # Test Case 1: Excellent performance\n    (0.8, 0, None),\n    # Test Case 2: Good, but borderline poor performance\n    (2.5, 1, \"medium\"),\n    # Test Case 3: Poor performance\n    (3.5, 1, \"high\"),\n    # Test Case 4: Extremely poor performance\n    (10.0, 1, \"high\"),\n    # Test Case 5: Perfect performance (boundary)",
        "detail": "Backend.tests.test_performance_monitor",
        "documentation": {}
    },
    {
        "label": "test_missing_security_header",
        "kind": 2,
        "importPath": "Backend.tests.test_security_checker",
        "description": "Backend.tests.test_security_checker",
        "peekOfCode": "def test_missing_security_header():\n    \"\"\"\n    Tests if the checker correctly identifies a missing security header.\n    \"\"\"\n    # Arrange: Create sample headers missing 'X-Frame-Options'\n    sample_headers = {\n        \"Content-Type\": \"text/html\",\n        \"Content-Security-Policy\": \"default-src 'self'\",\n        # Missing X-Frame-Options\n        \"Strict-Transport-Security\": \"max-age=31536000\",",
        "detail": "Backend.tests.test_security_checker",
        "documentation": {}
    },
    {
        "label": "test_all_security_headers_present",
        "kind": 2,
        "importPath": "Backend.tests.test_security_checker",
        "description": "Backend.tests.test_security_checker",
        "peekOfCode": "def test_all_security_headers_present():\n    \"\"\"\n    Tests if the checker finds no anomalies when all headers are present.\n    \"\"\"\n    # Arrange: Create headers with all required security headers\n    complete_headers = {\n        \"Content-Security-Policy\": \"default-src 'self'\",\n        \"X-Frame-Options\": \"DENY\",\n        \"Strict-Transport-Security\": \"max-age=31536000\",\n        \"X-Content-Type-Options\": \"nosniff\",",
        "detail": "Backend.tests.test_security_checker",
        "documentation": {}
    },
    {
        "label": "test_seo_scanner_multiple_issues",
        "kind": 2,
        "importPath": "Backend.tests.test_seo_scanner",
        "description": "Backend.tests.test_seo_scanner",
        "peekOfCode": "def test_seo_scanner_multiple_issues():\n    \"\"\"\n    Tests if the SEO scanner correctly identifies multiple issues from sample HTML.\n    \"\"\"\n    # Arrange: Create sample HTML with a short title and no meta description\n    sample_html = \"\"\"\n    <html>\n      <head>\n        <title>Hi</title>\n      </head>",
        "detail": "Backend.tests.test_seo_scanner",
        "documentation": {}
    },
    {
        "label": "n_samples",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "n_samples = 300\n# Generate synthetic features\n# security_count: integer 0 to 5\nsecurity_count = np.random.randint(0, 6, n_samples)\n# performance_count: integer 0 to 3\nperformance_count = np.random.randint(0, 4, n_samples)\n# avg_severity: simulate three levels: low (0.3), medium (0.6), high (0.9). \n# Randomly choose one for each sample.\nseverity_levels = [0.3, 0.6, 0.9]\navg_severity = np.random.choice(severity_levels, n_samples)",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "security_count",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "security_count = np.random.randint(0, 6, n_samples)\n# performance_count: integer 0 to 3\nperformance_count = np.random.randint(0, 4, n_samples)\n# avg_severity: simulate three levels: low (0.3), medium (0.6), high (0.9). \n# Randomly choose one for each sample.\nseverity_levels = [0.3, 0.6, 0.9]\navg_severity = np.random.choice(severity_levels, n_samples)\n# load_time_ms: integer between 500 and 5000 ms\nload_time_ms = np.random.randint(500, 5001, n_samples)\n# page_size_kb: integer between 50 and 1500 KB",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "performance_count",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "performance_count = np.random.randint(0, 4, n_samples)\n# avg_severity: simulate three levels: low (0.3), medium (0.6), high (0.9). \n# Randomly choose one for each sample.\nseverity_levels = [0.3, 0.6, 0.9]\navg_severity = np.random.choice(severity_levels, n_samples)\n# load_time_ms: integer between 500 and 5000 ms\nload_time_ms = np.random.randint(500, 5001, n_samples)\n# page_size_kb: integer between 50 and 1500 KB\npage_size_kb = np.random.randint(50, 1501, n_samples)\n# Now, define a risk score function for synthetic purposes:",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "severity_levels",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "severity_levels = [0.3, 0.6, 0.9]\navg_severity = np.random.choice(severity_levels, n_samples)\n# load_time_ms: integer between 500 and 5000 ms\nload_time_ms = np.random.randint(500, 5001, n_samples)\n# page_size_kb: integer between 50 and 1500 KB\npage_size_kb = np.random.randint(50, 1501, n_samples)\n# Now, define a risk score function for synthetic purposes:\n# Let’s say higher security_count and higher avg_severity increase risk,\n# as well as higher load time and larger page size.\n# We'll create a weighted sum and add some random noise.",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "avg_severity",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "avg_severity = np.random.choice(severity_levels, n_samples)\n# load_time_ms: integer between 500 and 5000 ms\nload_time_ms = np.random.randint(500, 5001, n_samples)\n# page_size_kb: integer between 50 and 1500 KB\npage_size_kb = np.random.randint(50, 1501, n_samples)\n# Now, define a risk score function for synthetic purposes:\n# Let’s say higher security_count and higher avg_severity increase risk,\n# as well as higher load time and larger page size.\n# We'll create a weighted sum and add some random noise.\n# Weights",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "load_time_ms",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "load_time_ms = np.random.randint(500, 5001, n_samples)\n# page_size_kb: integer between 50 and 1500 KB\npage_size_kb = np.random.randint(50, 1501, n_samples)\n# Now, define a risk score function for synthetic purposes:\n# Let’s say higher security_count and higher avg_severity increase risk,\n# as well as higher load time and larger page size.\n# We'll create a weighted sum and add some random noise.\n# Weights\nw_sec = 10\nw_perf = 8",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "page_size_kb",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "page_size_kb = np.random.randint(50, 1501, n_samples)\n# Now, define a risk score function for synthetic purposes:\n# Let’s say higher security_count and higher avg_severity increase risk,\n# as well as higher load time and larger page size.\n# We'll create a weighted sum and add some random noise.\n# Weights\nw_sec = 10\nw_perf = 8\nw_sev = 20\nw_load = 0.01  # per millisecond",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "w_sec",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "w_sec = 10\nw_perf = 8\nw_sev = 20\nw_load = 0.01  # per millisecond\nw_size = 0.02  # per kilobyte\n# Compute base risk (you can adjust the formula as needed)\nrisk_score = (\n    w_sec * security_count +\n    w_perf * performance_count +\n    w_sev * avg_severity +",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "w_perf",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "w_perf = 8\nw_sev = 20\nw_load = 0.01  # per millisecond\nw_size = 0.02  # per kilobyte\n# Compute base risk (you can adjust the formula as needed)\nrisk_score = (\n    w_sec * security_count +\n    w_perf * performance_count +\n    w_sev * avg_severity +\n    w_load * load_time_ms +",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "w_sev",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "w_sev = 20\nw_load = 0.01  # per millisecond\nw_size = 0.02  # per kilobyte\n# Compute base risk (you can adjust the formula as needed)\nrisk_score = (\n    w_sec * security_count +\n    w_perf * performance_count +\n    w_sev * avg_severity +\n    w_load * load_time_ms +\n    w_size * page_size_kb +",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "w_load",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "w_load = 0.01  # per millisecond\nw_size = 0.02  # per kilobyte\n# Compute base risk (you can adjust the formula as needed)\nrisk_score = (\n    w_sec * security_count +\n    w_perf * performance_count +\n    w_sev * avg_severity +\n    w_load * load_time_ms +\n    w_size * page_size_kb +\n    np.random.normal(0, 5, n_samples)  # add some noise",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "w_size",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "w_size = 0.02  # per kilobyte\n# Compute base risk (you can adjust the formula as needed)\nrisk_score = (\n    w_sec * security_count +\n    w_perf * performance_count +\n    w_sev * avg_severity +\n    w_load * load_time_ms +\n    w_size * page_size_kb +\n    np.random.normal(0, 5, n_samples)  # add some noise\n)",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "risk_score",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "risk_score = (\n    w_sec * security_count +\n    w_perf * performance_count +\n    w_sev * avg_severity +\n    w_load * load_time_ms +\n    w_size * page_size_kb +\n    np.random.normal(0, 5, n_samples)  # add some noise\n)\n# Ensure risk score is between 0 and 100\nrisk_score = np.clip(risk_score, 0, 100)",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "risk_score",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "risk_score = np.clip(risk_score, 0, 100)\n# Create a dataframe\ndata = pd.DataFrame({\n    \"security_count\": security_count,\n    \"performance_count\": performance_count,\n    \"avg_severity\": avg_severity,\n    \"load_time_ms\": load_time_ms,\n    \"page_size_kb\": page_size_kb,\n    \"risk_score\": risk_score\n})",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "data",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "data = pd.DataFrame({\n    \"security_count\": security_count,\n    \"performance_count\": performance_count,\n    \"avg_severity\": avg_severity,\n    \"load_time_ms\": load_time_ms,\n    \"page_size_kb\": page_size_kb,\n    \"risk_score\": risk_score\n})\n# Optionally, save the synthetic dataset for inspection\ndata.to_csv(\"risk_data.csv\", index=False)",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "X = data[[\"security_count\", \"performance_count\", \"avg_severity\", \"load_time_ms\", \"page_size_kb\"]]\ny = data[\"risk_score\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Train a RandomForestRegressor model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n# Evaluate the model\npreds = model.predict(X_test)\nmse = mean_squared_error(y_test, preds)\nrmse = np.sqrt(mse)",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "y = data[\"risk_score\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Train a RandomForestRegressor model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n# Evaluate the model\npreds = model.predict(X_test)\nmse = mean_squared_error(y_test, preds)\nrmse = np.sqrt(mse)\nprint(f\"Mean Squared Error: {mse:.2f}\")",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "model = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n# Evaluate the model\npreds = model.predict(X_test)\nmse = mean_squared_error(y_test, preds)\nrmse = np.sqrt(mse)\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"Root Mean Squared Error: {rmse:.2f}\")\n# Save the model to disk\njoblib.dump(model, \"risk_model.pkl\")",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "preds",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "preds = model.predict(X_test)\nmse = mean_squared_error(y_test, preds)\nrmse = np.sqrt(mse)\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"Root Mean Squared Error: {rmse:.2f}\")\n# Save the model to disk\njoblib.dump(model, \"risk_model.pkl\")\nprint(\"Model trained and saved as risk_model.pkl\")",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "mse",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "mse = mean_squared_error(y_test, preds)\nrmse = np.sqrt(mse)\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"Root Mean Squared Error: {rmse:.2f}\")\n# Save the model to disk\njoblib.dump(model, \"risk_model.pkl\")\nprint(\"Model trained and saved as risk_model.pkl\")",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "rmse",
        "kind": 5,
        "importPath": "Backend.risk_model",
        "description": "Backend.risk_model",
        "peekOfCode": "rmse = np.sqrt(mse)\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"Root Mean Squared Error: {rmse:.2f}\")\n# Save the model to disk\njoblib.dump(model, \"risk_model.pkl\")\nprint(\"Model trained and saved as risk_model.pkl\")",
        "detail": "Backend.risk_model",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "frontend.node_modules.flatted.python.flatted",
        "description": "frontend.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "frontend.node_modules.flatted.python.flatted",
        "documentation": {}
    }
]